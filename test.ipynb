{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f05a51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# --- Windows stability: force non-GUI backend BEFORE pyplot import ---\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from pandasai import SmartDataframe\n",
    "from PIL import Image\n",
    "\n",
    "from ollama_llm import OllamaLLM\n",
    "from groq_llm import GroqLLM\n",
    "\n",
    "st.set_page_config(page_title=\"AI CSV Analyst\", layout=\"wide\")\n",
    "st.title(\"ü§ñ Ask Anything About Your CSV (with Charts!)\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Settings\")\n",
    "    llm_choice = st.radio(\"Backend\", [\"Groq (hosted, fast)\", \"Ollama (local)\"], index=0)\n",
    "    groq_model = st.selectbox(\n",
    "        \"Groq model\",\n",
    "        [\"llama-3.1-70b-versatile\", \"llama-3.1-8b-instant\", \"mixtral-8x7b-32768\"],\n",
    "        index=0,\n",
    "    )\n",
    "    temperature = st.slider(\"Temperature\", 0.0, 1.0, 0.2, 0.05)\n",
    "    safe_mode = st.toggle(\n",
    "        \"Safe mode (no code execution)\",\n",
    "        value=False,\n",
    "        help=\"If on, the model answers in text only (no Python execution).\",\n",
    "    )\n",
    "\n",
    "# Instantiate LLM\n",
    "if llm_choice.startswith(\"Groq\"):\n",
    "    groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    if not groq_key:\n",
    "        st.error(\"‚ùå GROQ_API_KEY is not set. In cmd.exe:  set GROQ_API_KEY=your_key_here\")\n",
    "        st.stop()\n",
    "    llm = GroqLLM(model=groq_model, api_key=groq_key, temperature=temperature)\n",
    "    st.caption(\"Using Groq ‚Äî hosted, low-latency inference.\")\n",
    "else:\n",
    "    llm = OllamaLLM(model=\"llama3\", api_base=\"http://localhost:11434\")\n",
    "    st.caption(\"Using local Ollama runtime.\")\n",
    "\n",
    "# Session state\n",
    "if \"chart_png\" not in st.session_state:\n",
    "    st.session_state.chart_png = None\n",
    "if \"answer_text\" not in st.session_state:\n",
    "    st.session_state.answer_text = None\n",
    "\n",
    "# File upload\n",
    "uploaded_file = st.file_uploader(\"üìÇ Upload a CSV file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        @st.cache_data(show_spinner=False)\n",
    "        def _read_csv(_f):\n",
    "            return pd.read_csv(_f)\n",
    "\n",
    "        df = _read_csv(uploaded_file)\n",
    "        st.success(\"‚úÖ CSV uploaded successfully!\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        prompt = st.text_area(\n",
    "            \"üí¨ Ask a question or request a chart:\",\n",
    "            placeholder=\"e.g., Create a bar chart of counts in Column B\",\n",
    "            height=100,\n",
    "        )\n",
    "\n",
    "        if st.button(\"Generate Answer\", type=\"primary\"):\n",
    "            if prompt.strip():\n",
    "                with st.spinner(\"üß† Thinking...\"):\n",
    "                    try:\n",
    "                        smart_df = SmartDataframe(\n",
    "                            df,\n",
    "                            config={\n",
    "                                \"llm\": llm,\n",
    "                                \"enable_code_execution\": not safe_mode,  # Safe Mode = text only\n",
    "                                \"save_charts\": False,\n",
    "                                \"use_error_correction_framework\": False,  # faster\n",
    "                                \"max_retries\": 1,\n",
    "                                \"verboseness\": \"low\",\n",
    "                            },\n",
    "                        )\n",
    "\n",
    "                        try:\n",
    "                            response = smart_df.chat(prompt)\n",
    "                        except SystemExit:\n",
    "                            st.error(\"The generated code attempted to terminate the app. Stopping safely.\")\n",
    "                            st.stop()\n",
    "                        except BaseException as e:\n",
    "                            st.exception(e)\n",
    "                            st.stop()\n",
    "\n",
    "                        if isinstance(response, pd.DataFrame):\n",
    "                            st.session_state.answer_text = None\n",
    "                            st.dataframe(response)\n",
    "                        else:\n",
    "                            st.session_state.answer_text = response\n",
    "\n",
    "                        # --- Robust figure capture ---\n",
    "                        try:\n",
    "                            fig = None\n",
    "                            nums = plt.get_fignums()\n",
    "                            if nums:\n",
    "                                fig = plt.figure(nums[-1])\n",
    "\n",
    "                            if fig and fig.get_axes():\n",
    "                                buf = io.BytesIO()\n",
    "                                fig.set_dpi(150)\n",
    "                                fig.savefig(buf, format=\"png\", bbox_inches=\"tight\", facecolor=\"white\")\n",
    "                                buf.seek(0)\n",
    "                                st.session_state.chart_png = buf.read()\n",
    "                            else:\n",
    "                                st.session_state.chart_png = None\n",
    "                                st.info(\"‚ÑπÔ∏è No chart was generated for this prompt.\")\n",
    "                        finally:\n",
    "                            plt.close(\"all\")  # ensure no lingering figures\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"‚ùå Error during chat or chart rendering: {e}\")\n",
    "            else:\n",
    "                st.warning(\"‚ö†Ô∏è Please enter a prompt.\")\n",
    "\n",
    "        # Show answer\n",
    "        if st.session_state.answer_text:\n",
    "            st.success(\"‚úÖ Answer:\")\n",
    "            st.write(st.session_state.answer_text)\n",
    "\n",
    "        # Zoom controls + image\n",
    "        if st.session_state.chart_png:\n",
    "            c1, c2, c3 = st.columns([1, 1, 2])\n",
    "            with c1:\n",
    "                width_px = st.slider(\"üîç Zoom width (px)\", 300, 2000, 900, step=50, key=\"zoom_width\")\n",
    "            with c2:\n",
    "                keep_aspect = st.checkbox(\"Keep aspect ratio\", True, key=\"keep_aspect\")\n",
    "            with c3:\n",
    "                if not keep_aspect:\n",
    "                    height_px = st.slider(\"Height (px)\", 200, 1500, 500, step=20, key=\"zoom_height\")\n",
    "                else:\n",
    "                    height_px = None\n",
    "\n",
    "            if keep_aspect:\n",
    "                st.image(st.session_state.chart_png, width=width_px)\n",
    "            else:\n",
    "                try:\n",
    "                    img = Image.open(io.BytesIO(st.session_state.chart_png))\n",
    "                    img = img.resize((int(width_px), int(height_px)), Image.BICUBIC)\n",
    "                    out = io.BytesIO()\n",
    "                    img.save(out, format=\"PNG\")\n",
    "                    out.seek(0)\n",
    "                    st.image(out, width=None)\n",
    "                except Exception:\n",
    "                    st.image(st.session_state.chart_png, width=width_px)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå Error loading CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8583e15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasai import SmartDataframe\n",
    "# from ollama_llm import OllamaLLM   # ‚Üê keep if you want to switch back locally\n",
    "from groq_llm import GroqLLM        # ‚Üê use Groq\n",
    "\n",
    "# Optional: for non-proportional resizing when \"Keep aspect ratio\" is OFF\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------- Page & LLM --------------------\n",
    "st.set_page_config(page_title=\"AI CSV Analyst\", layout=\"wide\")\n",
    "st.title(\"ü§ñ Ask Anything About Your CSV (with Charts!)\")\n",
    "\n",
    "# Read Groq key from Streamlit secrets OR env var\n",
    "groq_api_key = None\n",
    "try:\n",
    "    groq_api_key = st.secrets.get(\"GROQ_API_KEY\")\n",
    "except Exception:\n",
    "    pass\n",
    "groq_api_key = groq_api_key or os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Use Groq (OpenAI-compatible). Pick any Groq model you like:\n",
    "# \"llama-3.1-8b-instant\", \"llama-3.1-70b-versatile\", \"mixtral-8x7b-32768\"\n",
    "llm = GroqLLM(model=\"llama-3.1-8b-instant\", api_key=groq_api_key)\n",
    "\n",
    "# If you want to switch back to local Ollama, comment the line above and uncomment:\n",
    "# llm = OllamaLLM(model=\"llama3\", api_base=\"http://localhost:11434\")\n",
    "\n",
    "# -------------------- Session state --------------------\n",
    "if \"chart_png\" not in st.session_state:\n",
    "    st.session_state.chart_png = None\n",
    "if \"answer_text\" not in st.session_state:\n",
    "    st.session_state.answer_text = None\n",
    "\n",
    "# -------------------- File upload --------------------\n",
    "uploaded_file = st.file_uploader(\"üìÇ Upload a CSV file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.success(\"‚úÖ CSV uploaded successfully!\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        prompt = st.text_area(\n",
    "            \"üí¨ Ask a question or request a chart:\",\n",
    "            placeholder=\"e.g., Create a bar chart of counts in Column B\",\n",
    "            height=100,\n",
    "        )\n",
    "\n",
    "        if st.button(\"Generate Answer\"):\n",
    "            if prompt.strip():\n",
    "                with st.spinner(\"üß† Thinking...\"):\n",
    "                    try:\n",
    "                        smart_df = SmartDataframe(\n",
    "                            df,\n",
    "                            config={\n",
    "                                \"llm\": llm,\n",
    "                                \"enable_code_execution\": True,  # allow plotting code\n",
    "                            },\n",
    "                        )\n",
    "\n",
    "                        # A) Clean matplotlib state each run\n",
    "                        plt.close('all')\n",
    "\n",
    "                        # Ask the model\n",
    "                        response = smart_df.chat(prompt)\n",
    "\n",
    "                        # B) Gentle retry if PandasAI returned its failure string\n",
    "                        if isinstance(response, str) and \"All objects passed were None\" in response:\n",
    "                            retry_prompt = (\n",
    "                                prompt\n",
    "                                + \"\\n\\nIf a chart or dataframe is not straightforward, \"\n",
    "                                  \"answer concisely in plain text. Do NOT return None.\"\n",
    "                            )\n",
    "                            plt.close('all')  # also start retry clean\n",
    "                            response = smart_df.chat(retry_prompt)\n",
    "\n",
    "                        # Minimal guard for a None reply\n",
    "                        if response is None:\n",
    "                            st.info(\"The model returned no structured answer for this prompt. Try rephrasing.\")\n",
    "                            st.session_state.answer_text = None\n",
    "                            st.session_state.chart_png = None\n",
    "                            st.stop()\n",
    "\n",
    "                        # Store textual answer or show DataFrame directly\n",
    "                        if isinstance(response, pd.DataFrame):\n",
    "                            st.session_state.answer_text = None\n",
    "                            st.dataframe(response)\n",
    "                        else:\n",
    "                            st.session_state.answer_text = response\n",
    "\n",
    "                        # Capture the latest matplotlib figure (if any) and persist as PNG\n",
    "                        fig = None\n",
    "                        fig_nums = plt.get_fignums()\n",
    "                        if fig_nums:\n",
    "                            fig = plt.figure(fig_nums[-1])  # last created fig\n",
    "\n",
    "                        if fig and fig.get_axes():\n",
    "                            buf = io.BytesIO()\n",
    "                            # render at decent DPI so zoom looks crisp\n",
    "                            fig.set_dpi(150)\n",
    "                            fig.savefig(buf, format=\"png\", bbox_inches=\"tight\", facecolor=\"white\")\n",
    "                            buf.seek(0)\n",
    "                            st.session_state.chart_png = buf.read()\n",
    "                            plt.close(fig)\n",
    "                        else:\n",
    "                            st.session_state.chart_png = None\n",
    "                            st.info(\"‚ÑπÔ∏è No chart was generated for this prompt.\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"‚ùå Error during chat or chart rendering: {e}\")\n",
    "            else:\n",
    "                st.warning(\"‚ö†Ô∏è Please enter a prompt.\")\n",
    "\n",
    "        # -------------------- Show answer --------------------\n",
    "        if st.session_state.answer_text:\n",
    "            st.success(\"‚úÖ Answer:\")\n",
    "            st.write(st.session_state.answer_text)\n",
    "\n",
    "        # -------------------- Zoom controls ABOVE the image --------------------\n",
    "        if st.session_state.chart_png:\n",
    "            # Controls live right above the image\n",
    "            c1, c2, c3 = st.columns([1, 1, 2])\n",
    "            with c1:\n",
    "                width_px = st.slider(\"üîç Zoom width (px)\", 300, 2000, 900, step=50, key=\"zoom_width\")\n",
    "            with c2:\n",
    "                keep_aspect = st.checkbox(\"Keep aspect ratio\", True, key=\"keep_aspect\")\n",
    "            with c3:\n",
    "                if not keep_aspect:\n",
    "                    height_px = st.slider(\"Height (px)\", 200, 1500, 500, step=20, key=\"zoom_height\")\n",
    "                else:\n",
    "                    height_px = None  # ignored\n",
    "\n",
    "            # Render persisted PNG with chosen zoom\n",
    "            if keep_aspect:\n",
    "                st.image(st.session_state.chart_png, width=width_px)\n",
    "            else:\n",
    "                # Resize to (width_px, height_px) using Pillow\n",
    "                try:\n",
    "                    img = Image.open(io.BytesIO(st.session_state.chart_png))\n",
    "                    img = img.resize((int(width_px), int(height_px)), Image.BICUBIC)\n",
    "                    out = io.BytesIO()\n",
    "                    img.save(out, format=\"PNG\")\n",
    "                    out.seek(0)\n",
    "                    st.image(out, width=None)  # already resized to exact pixels\n",
    "                except Exception:\n",
    "                    # Fallback if Pillow not available or fails\n",
    "                    st.image(st.session_state.chart_png, width=width_px)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"‚ùå Error loading CSV: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
